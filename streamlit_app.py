import streamlit as st
import torch
from transformers import BertTokenizer, BertForSequenceClassification
import numpy as np
import joblib

# âœ… ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ
category_encoder = joblib.load("category_encoder.pkl")
target_encoder = joblib.load("target_encoder.pkl")

# âœ… ëª¨ë¸ & í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = BertTokenizer.from_pretrained('klue/bert-base')
model = torch.load("hate_speech_model.pt", map_location='cpu')
model.eval()

st.title("í˜ì˜¤ í‘œí˜„ íƒì§€ê¸°")
st.write("ğŸ—¨ï¸ ì˜¨ë¼ì¸ ì»¤ë®¤ë‹ˆí‹°ë‚˜ ì†Œì…œë¯¸ë””ì–´ì—ì„œ ì ‘í•œ í˜ì˜¤ í‘œí˜„ì´ ì˜ì‹¬ë˜ëŠ” ë¬¸ì¥ì„ ì…ë ¥í•´ë³´ì„¸ìš”!")

text = st.text_input("ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”:")

if st.button("ë¶„ì„í•˜ê¸°"):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits

        # âœ… category ì¶œë ¥
        predicted_category_idx = torch.argmax(logits[0]).item()
        predicted_category = category_encoder.inverse_transform([predicted_category_idx])[0]

        # âœ… target ì¶œë ¥ (ë§Œì•½ ë‘ ë²ˆì§¸ ì¶œë ¥ì´ targetì´ë¼ë©´)
        predicted_target_idx = torch.argmax(logits[1]).item()
        predicted_target = target_encoder.inverse_transform([predicted_target_idx])[0]

    st.write(f"âœ… ì˜ˆì¸¡ëœ í˜ì˜¤ í‘œí˜„ ì¹´í…Œê³ ë¦¬: **{predicted_category}**")
    st.write(f"âœ… ì˜ˆì¸¡ëœ í˜ì˜¤ í‘œí˜„ ëŒ€ìƒ: **{predicted_target}**")